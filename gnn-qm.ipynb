{"cells":[{"cell_type":"markdown","metadata":{"id":"a7c1929d-3ec6-4fdc-aec6-34529d13b646"},"source":["# Import Libararies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37cf0a92-70fe-4e42-8d9e-818366cf04ec"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import glob\n","import json\n","import csv\n","from IPython import display\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","import math\n","from biopandas.mol2 import PandasMol2"]},{"cell_type":"markdown","metadata":{"id":"4b9db7f1-b47e-404c-a300-499056926daf"},"source":["# Dataframe: Extracting CIFs files + Formation Energy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c094bd30-ed7d-45a2-9832-157ee3a586fe","outputId":"321aced3-dd6c-4be4-89c6-e5140396d5ec"},"outputs":[],"source":["energy = pd.read_csv('PATH/energies/AllECell_long.txt', sep=\" \",  header = None)\r\n","energy.columns = [\"a\", \"cif-path\", \"c\", \"energy\"]\r\n","# Drop Unnecessary columns\r\n","energy = energy.drop(columns=[\"a\", \"c\"])\r\n","energy.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68980f96-90d7-4b0e-ae85-c7002b486b77","outputId":"d4efa8c8-84d3-4b4a-e238-391ea6902595"},"outputs":[],"source":["energy_data = energy[\"cif-path\"].str.split(\".\", n = 1, expand = True)\n","energy_data.columns = [\"cif-id\", \"string_outmol\"]\n","energy_data = energy_data.drop(columns=[\"string_outmol\"])\n","energy_data['energy'] = energy['energy']\n","energy_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72509050-1e77-4207-bfab-d61992217f40","outputId":"ce5b5e18-ceb6-4def-adb7-31dc0bf391e3"},"outputs":[],"source":["# Cif dataset\r\n","all_cifs = [f for f in glob.glob('PATH/cif-files/*.cif')]\r\n","\r\n","cif_idx = []\r\n","for file in range(len(all_cifs)):\r\n","    name, ext = os.path.splitext(all_cifs[file])\r\n","    name = name.split('/')\r\n","    name = name[2]\r\n","    cif_idx.append(name)\r\n","    \r\n","\r\n","#print(len(all_cifs))\r\n","# Creating dataframe\r\n","nsample = len(all_cifs)\r\n","cif_data = pd.DataFrame(\r\n","    np.concatenate([np.expand_dims(np.array(all_cifs), axis=1), np.expand_dims(np.array(cif_idx), axis=1)], axis=1), \r\n","    columns=[\"cif-path\"] + [\"cif-id\"]\r\n",")\r\n","cif_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e77d658-4da6-478a-b934-ba583a6844d4","outputId":"d5aade05-80fe-40cc-e1ec-8e7158f95b20"},"outputs":[],"source":["data = pd.merge(cif_data, energy_data, on=\"cif-id\")\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9364f37-ec87-4441-9fec-5e67b8afb1f3","outputId":"ed15a8e3-b42c-4a37-92e8-d3e636a0b1f4"},"outputs":[],"source":["# chnage the columns order\n","cols = data.columns.tolist()\n","myorder = [0, 2, 1]\n","cols = [cols[i] for i in myorder]\n","\n","final_data = data[cols] \n","# rename the columns\n","final_data = final_data.rename(columns = {'cif-path':'structure', 'energy':'formation_energy', 'cif-id':'cif-id'})\n","final_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27062b76-1655-4f59-a9ba-7edb519e0e89","outputId":"046e8f99-8aea-4e72-f6b2-207d36411168"},"outputs":[],"source":["final_data.info()"]},{"cell_type":"markdown","metadata":{"id":"80759e6d-0909-4d1c-8ea4-f4d98a739332"},"source":["# Train-Valid-Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6a99080-9fb7-4359-9881-0300dbc508d8","outputId":"1c406f31-1b4a-4e39-f7d7-43c128eb057c"},"outputs":[],"source":["df = final_data.copy()\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9716aa85-e12f-4fb4-ac0d-c225f040b188"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\t\n","\n","tmp, test_df = train_test_split(df, test_size=0.2, random_state=101)\n","train_df, valid_df = train_test_split(tmp, test_size=0.1, random_state=101)\n","\n","train_df.to_csv(\"dataset/org-train.csv\", encoding=\"utf-8\", index=False)\n","valid_df.to_csv(\"dataset/org-valid.csv\", encoding=\"utf-8\", index=False)\n","test_df.to_csv(\"dataset/org-test.csv\", encoding=\"utf-8\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"47714011-18db-416a-972b-ebb088fc7812"},"source":["# Preprocessing Formation Energy: StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22987407-01ee-4bc8-9034-86f74b54ae08"},"outputs":[],"source":["from sklearn import preprocessing\n","x_cols = list(train_df.columns)[1]\n","scaler = preprocessing.StandardScaler()\n","scaler.fit(train_df[[x_cols]])\n","\n","\n","new_train_df = train_df.copy()\n","new_train_df[[x_cols]] = scaler.transform(train_df[[x_cols]])\n","\n","new_valid_df = valid_df.copy()\n","new_valid_df[[x_cols]] = scaler.transform(valid_df[[x_cols]])\n","\n","new_test_df = test_df.copy()\n","new_test_df[[x_cols]] = scaler.transform(test_df[[x_cols]])\n","\n","\n","new_train_df.to_csv(\"dataset/train.csv\", encoding=\"utf-8\", index=False)\n","new_valid_df.to_csv(\"dataset/valid.csv\", encoding=\"utf-8\", index=False)\n","new_test_df.to_csv(\"dataset/test.csv\", encoding=\"utf-8\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01dc2c7a-17b4-4ba1-8c2d-163602a1e444","outputId":"13dc4835-e450-4b74-ea57-7e8d17560656"},"outputs":[],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8b7b3cec-6450-4504-a014-80a6a09c5a41","outputId":"5f1a6a29-98b5-4ea9-e5f8-3faa32e9aa33"},"outputs":[],"source":["new_train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abf167d4-91c6-451b-b0ee-433312b4d97b","outputId":"e64ab352-c6fe-4b30-ec5d-161707e4fd3d"},"outputs":[],"source":["new_train_df.shape, new_valid_df.shape, new_test_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89f3e48c-4b4a-4a17-a6ee-3a9a7c856806","outputId":"11fccdc3-8940-467e-bf44-c434325f6acf"},"outputs":[],"source":["train_df.shape, valid_df.shape,test_df.shape"]},{"cell_type":"markdown","metadata":{"id":"307aad03-e445-4868-aaa6-0b8596432e9e"},"source":["# Torch Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ea5fa50-878a-441e-a66f-40a666d5e5e3"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","from pymatgen.core.structure import Structure\n","\n","import pandas as pd\n","import numpy as np\n","import json\n","import warnings\n","\n","\n","class GaussianDistance(object):\n","    \n","    def __init__(self, dmin, dmax, step, var=None):\n","        \"\"\"\n","        Parameters\n","        ----------\n","\n","        dmin: float\n","          Minimum interatomic distance\n","        dmax: float\n","          Maximum interatomic distance\n","        step: float\n","          Step size for the filter\n","        \"\"\"\n","        assert dmin < dmax\n","        assert dmax - dmin > step\n","        self.filter = np.arange(dmin, dmax+step, step)\n","        if var is None:\n","            var = step\n","        self.var = var\n","\n","    def expand(self, distances):\n","        \"\"\"\n","        Apply disntance filter to a numpy distance array\n","\n","        Parameters\n","        ----------\n","\n","        distance: A distance matrix of any shape\n","\n","        Returns\n","        -------\n","        expanded_distance: \n","        Expanded distance matrix with the last dimension of length\n","        len(self.filter)\n","        \"\"\"\n","        return np.exp(-(distances[..., np.newaxis] - self.filter)**2 /\n","                      self.var**2)\n","\n","\n","class AtomInitializer(object):\n","    \"\"\"\n","    Base class for intializing the vector representation for atoms.\n","    \"\"\"\n","    def __init__(self, atom_types):\n","        self.atom_types = set(atom_types)\n","        self._embedding = {}\n","\n","    def get_atom_fea(self, atom_type):\n","        assert atom_type in self.atom_types\n","        return self._embedding[atom_type]\n","\n","    def load_state_dict(self, state_dict):\n","        self._embedding = state_dict\n","        self.atom_types = set(self._embedding.keys())\n","        self._decodedict = {idx: atom_type for atom_type, idx in\n","                            self._embedding.items()}\n","\n","    def state_dict(self):\n","        return self._embedding\n","\n","    def decode(self, idx):\n","        if not hasattr(self, '_decodedict'):\n","            self._decodedict = {idx: atom_type for atom_type, idx in\n","                                self._embedding.items()}\n","        return self._decodedict[idx]\n","\n","\n","class AtomCustomJSONInitializer(AtomInitializer):\n","    \"\"\"\n","    Initialize atom feature vectors using a JSON file, which is a python\n","    dictionary mapping from element number to a list representing the\n","    feature vector of the element.\n","\n","    Parameters\n","    ----------\n","\n","    elem_embedding_file: str\n","        The path to the .json file\n","    \"\"\"\n","    def __init__(self, elem_embedding_file):\n","        with open(elem_embedding_file) as f:\n","            elem_embedding = json.load(f)\n","        elem_embedding = {int(key): value for key, value\n","                          in elem_embedding.items()}\n","        atom_types = set(elem_embedding.keys())\n","        super(AtomCustomJSONInitializer, self).__init__(atom_types)\n","        for key, value in elem_embedding.items():\n","            self._embedding[key] = np.array(value, dtype=float)\n","            \n","\n","class CrystalDataset(Dataset):\n","\n","    def __init__(self, data_path, atom_init_file=\"./atom_init.json\", max_num_nbr=12, radius=8, dmin=0, step=0.2):\n","        #self.df = pd.read_json(data_path, orient='records', lines=True)\n","        self.df = pd.read_csv(data_path)\n","        self.max_num_nbr, self.radius = max_num_nbr, radius\n","        \n","        self.ari = AtomCustomJSONInitializer(atom_init_file)\n","        self.gdf = GaussianDistance(dmin=dmin, dmax=self.radius, step=step)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        sample = self.df.iloc[idx].values\n","        #struct, target, cif_id = sample[0], sample[1:-1], sample[-1]\n","        struct, target, cif_id = sample[0], sample[1], sample[2]\n","\n","        crystal = Structure.from_file(struct)\n","        #crystal = Structure.from_dict(struct)\n","        atom_fea = np.vstack([self.ari.get_atom_fea(crystal[i].specie.number) for i in range(len(crystal))]) # Stack arrays in sequence vertically (row wise).\n","        atom_fea = torch.Tensor(atom_fea)\n","        all_nbrs = crystal.get_all_neighbors(self.radius, include_index=True)\n","        all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]\n","        nbr_fea_idx, nbr_fea = [], []\n","        for nbr in all_nbrs:\n","            if len(nbr) < self.max_num_nbr:\n","                warnings.warn('{} not find enough neighbors to build graph. '\n","                              'If it happens frequently, consider increase '\n","                              'radius.'.format(cif_id))\n","                nbr_fea_idx.append(list(map(lambda x: x[2], nbr)) +\n","                                   [0] * (self.max_num_nbr - len(nbr)))\n","                nbr_fea.append(list(map(lambda x: x[1], nbr)) +\n","                               [self.radius + 1.] * (self.max_num_nbr -\n","                                                     len(nbr)))\n","            else:\n","                nbr_fea_idx.append(list(map(lambda x: x[2],\n","                                            nbr[:self.max_num_nbr])))\n","                nbr_fea.append(list(map(lambda x: x[1],\n","                                        nbr[:self.max_num_nbr])))\n","        nbr_fea_idx, nbr_fea = np.array(nbr_fea_idx), np.array(nbr_fea)\n","        nbr_fea = self.gdf.expand(nbr_fea)\n","        atom_fea = torch.Tensor(atom_fea)\n","        nbr_fea = torch.Tensor(nbr_fea)\n","        nbr_fea_idx = torch.LongTensor(nbr_fea_idx)\n","        #target = torch.Tensor(np.array(target, dtype=float))\n","        target = torch.Tensor([float(target)])\n","\n","        x, edge_attr, edge_index = atom_fea, nbr_fea, nbr_fea_idx\n","        return (x, edge_attr, edge_index), target, cif_id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7b0d1705-b990-4975-93ea-958b01852376"},"outputs":[],"source":["# Define the Dataset with maximum number of 12 and radius 8\n","train_dataset = CrystalDataset(\"dataset/train.csv\", max_num_nbr=12, radius=8)\n","valid_dataset = CrystalDataset(\"dataset/valid.csv\", max_num_nbr=12, radius=8)\n","test_dataset = CrystalDataset(\"dataset/test.csv\", max_num_nbr=12, radius=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fbd829f-03d8-4750-95c3-64bfb5a074fa","outputId":"5040e6c4-a51f-4519-ef9a-cfa8488e3124"},"outputs":[],"source":["# look at dataset shape: sanple(train_dataset)\n","print(train_dataset[0][0][0].shape) # node feature\n","print(train_dataset[0][0][1].shape) # edge feature\n","print(train_dataset[0][0][2].shape) # edge index\n","print(train_dataset[0][1].shape) # target\n","print(train_dataset[0][2]) # CIFs id"]},{"cell_type":"markdown","metadata":{"id":"a684b51e-964a-4603-98bc-8fc6dbcf07ec"},"source":["# Torch DataLoder "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7fbb660-bae3-407f-9f42-dc4cb9529de0"},"outputs":[],"source":["def collate_fn(data_list):\n","    \"\"\"\n","    collate-fn function will enable custom batching.\n","    \"\"\"\n","    batch_x, batch_edge_attr, batch_edge_index = [], [], []\n","    crystal_x_idx, batch_target = [], []\n","    batch_ids = []\n","    base_idx = 0\n","    \n","    for i, ((x, edge_attr, edge_index), target, _id) in enumerate(data_list):\n","        n_i = x.shape[0]\n","        batch_x.append(x)\n","        batch_edge_attr.append(edge_attr)\n","        batch_edge_index.append(edge_index + base_idx)\n","        \n","        new_idx = torch.LongTensor(np.arange(n_i) + base_idx)\n","        crystal_x_idx.append(new_idx)\n","        batch_target.append(target)\n","        batch_ids.append(_id)\n","        base_idx += n_i\n","    \n","    \n","    batch_x = torch.cat(batch_x, dim=0)\n","    batch_edge_attr = torch.cat(batch_edge_attr, dim=0)\n","    batch_edge_index = torch.cat(batch_edge_index, dim=0)\n","    batch_target = torch.stack(batch_target, dim=0)\n","    \n","    return (batch_x, batch_edge_attr, batch_edge_index, crystal_x_idx), batch_target, batch_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"279155ae-28c3-4bb7-a46a-fbd147121e10"},"outputs":[],"source":["# define batch-size = 32, you could choose batch size [32, 64, 128, 256, ...]\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ca34777-855e-4224-8266-1c6aac8ac732","outputId":"426424c3-75bf-453d-d501-c40508e30595"},"outputs":[],"source":["for batch in train_loader:\n","    print(\"x\", batch[0][0].shape) # Result of baching with size=32 on node feature (x)\n","    print(\"edge_attr\", batch[0][1].shape) # Result of baching with size=32 on edge feature \n","    print(\"edge_index\", batch[0][2].shape) # Result of baching with size=32 on edge index \n","    #print(\"crystal_x_idx\", batch[0][3])\n","    \n","    #print(batch[1])\n","    #print(batch[2])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"024dd4c2-cc7b-41ac-bb4d-476b99806f2b"},"source":["# CGConv Neural Network Model Design"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"866c4662-de13-4a38-a77a-a49bf97143a3","outputId":"5ef248f9-72bd-4bdf-c43f-d570d64b6d53"},"outputs":[],"source":["structures, _, _ = train_dataset[0]\n","original_x_len = structures[0].shape[-1]\n","edge_attr_len = structures[1].shape[-1]\n","\n","print(original_x_len, edge_attr_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e538293-5220-465c-9328-8d08a54debc7"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","\n","import pytorch_lightning as pl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1089f8d-253f-4c95-95a6-70ca95f1ec14"},"outputs":[],"source":["class ConvLayer(nn.Module):\n","    def __init__(self, x_len, edge_attr_len):\n","        super(ConvLayer, self).__init__()\n","        \n","        self.x_len = x_len\n","        self.edge_attr_len = edge_attr_len\n","        self.fc = nn.Linear(2 * self.x_len + self.edge_attr_len, 2 * self.x_len)\n","        self.sigmoid = nn.Sigmoid()\n","        self.softplus1 = nn.Softplus()\n","        self.bn1 = nn.BatchNorm1d(2 * self.x_len)\n","        self.bn2 = nn.BatchNorm1d(self.x_len)\n","        self.softplus2 = nn.Softplus()\n","    \n","    def forward(self, x, edge_attr, edge_index):\n","        N, M = edge_index.shape\n","        \n","        x_nbr = x[edge_index, :]\n","        nbrs = torch.cat([x.unsqueeze(1).expand(N, M, self.x_len), x_nbr, edge_attr], dim=2)\n","        gated = self.fc(nbrs)\n","        gated = self.bn1(gated.view(-1, self.x_len * 2)).view(N, M, self.x_len * 2)\n","        \n","        nbr_filter, nbr_core = gated.chunk(2, dim=2)\n","        nbr_filter = self.sigmoid(nbr_filter)\n","        nbr_core = self.softplus1(nbr_core)\n","        \n","        nbr_sum = torch.sum(nbr_filter * nbr_core, dim=1)\n","        nbr_sum = self.bn2(nbr_sum)\n","        out = self.softplus2(x + nbr_sum)\n","        return out\n","        \n","\n","class CrystalGraphConvNet(pl.LightningModule):\n","\n","    def __init__(\n","        self, \n","        original_x_len,\n","        edge_attr_len,\n","        out_dim=1,\n","        x_len=64,\n","        n_conv=3,\n","        n_h_features=128,\n","        n_h_layers=1,\n","        learning_rate=1e-3,\n","        bias=True\n","    ):\n","        # Inheritances\n","        super().__init__()\n","\n","        # Params\n","        self.learning_rate = learning_rate\n","\n","        # Embedding\n","        self.embedding = nn.Linear(original_x_len, x_len)\n","\n","        # CGC layer\n","        self.convs = nn.ModuleList([\n","            ConvLayer(x_len=x_len, edge_attr_len=edge_attr_len)\n","            for _ in range(n_conv)\n","        ])        \n","\n","        self.fc = nn.ModuleList(\n","            [nn.Linear(x_len, n_h_features)]\n","            +\n","            [nn.Linear(n_h_features, n_h_features) for _ in range(n_h_layers - 1)]\n","        )\n","        self.ac = nn.ModuleList(\n","            [nn.Softplus()]\n","            +\n","            [nn.Softplus() for _ in range(n_h_layers - 1)]\n","        )\n","        \n","        self.out = nn.Linear(n_h_features, out_dim)\n","\n","    def forward(self, x, edge_attr, edge_index, crystal_x_idx):\n","        \n","        hidden = self.embedding(x)\n","        \n","        \n","        for conv in self.convs:\n","            hidden = conv(hidden, edge_attr, edge_index)\n","            \n","        # Pooling\n","        hidden =self.pooling(hidden, crystal_x_idx)\n","        \n","        # Fully-connection\n","        for fc, ac in zip(self.fc, self.ac):\n","            hidden = ac(fc(hidden))\n","\n","        # Apply a final (linear) classifier.\n","        out = self.out(hidden)\n","\n","        return out\n","    \n","    def pooling(self, x, crystal_x_idx):\n","        assert sum([len(idx) for idx in crystal_x_idx]) == x.data.shape[0]\n","\n","        hidden = torch.cat(\n","            [torch.mean(x[idx], dim=0, keepdim=True) for idx in crystal_x_idx],\n","            dim=0\n","        )\n","\n","        return hidden\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=0.01)\n","        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n","        return (\n","            {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n","        )\n","\n","    def training_step(self, batch, batch_idx):\n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        y_hat = self(x, edge_attr, edge_index, crystal_x_idx)\n","\n","        loss = F.mse_loss(y_hat, y)\n","        loss_mae = F.l1_loss(y_hat, y)\n","        self.log(\n","            'train_loss_mse', loss, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        self.log(\n","            'train_loss_mae', loss_mae, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        y_hat = self(x, edge_attr, edge_index, crystal_x_idx)\n","\n","        loss = F.mse_loss(y_hat, y)\n","        loss_mae = F.l1_loss(y_hat, y)\n","        self.log(\n","            'val_loss_mse', loss, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        self.log(\n","            'val_loss_mae', loss_mae, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        y_hat = self(x, edge_attr, edge_index, crystal_x_idx)\n","\n","        loss = F.mse_loss(y_hat, y)\n","        loss_mae = F.l1_loss(y_hat, y)\n","        self.log(\n","            'test_loss_mse', loss, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        self.log(\n","            'test_loss_mae', loss_mae, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61f602d1-2c9b-41a3-a54f-25b8a055cf09"},"outputs":[],"source":["from dataclasses import dataclass\n","\n","\n","@dataclass\n","class ModelConfig:\n","    original_x_len = original_x_len\n","    edge_attr_len = edge_attr_len\n","    out_dim = 1\n","    x_len = 64\n","    n_conv = 3\n","    n_h_features = 128\n","    n_h_layers = 1\n","    learning_rate = 1e-3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08507ca4-b163-4f5d-a9f5-fa66dc620be0","outputId":"c63dfffc-47f9-47a2-e501-b00f39a88ee5"},"outputs":[],"source":["# print the model\n","model = CrystalGraphConvNet( \n","    original_x_len=ModelConfig.original_x_len,\n","    edge_attr_len=ModelConfig.edge_attr_len,\n","    out_dim=ModelConfig.out_dim,\n","    x_len=ModelConfig.x_len,\n","    n_conv=ModelConfig.n_conv,\n","    n_h_features=ModelConfig.n_h_features,\n","    n_h_layers=ModelConfig.n_h_layers,\n","    learning_rate=ModelConfig.learning_rate,\n",")\n","print(model)\n","print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cedfb378-bfbc-410e-ae84-ab7c5a75a6c5","outputId":"b220cd6d-3289-407d-a3a6-f11a4e4b770a"},"outputs":[],"source":["for batch in train_loader:\n","    (batch_x, batch_edge_attr, batch_edge_index, crystal_x_idx), batch_target, batch_ids = batch\n","\n","    out = model(batch_x, batch_edge_attr, batch_edge_index, crystal_x_idx)\n","    print(out.shape)\n","    print(out[:5])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"4c25920a-2125-4ea0-9a72-45db3a0c149d"},"source":["# Training Stage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e89014ac-8387-469f-80df-8f3be583bb8a","outputId":"1d08e9e0-5f1a-4c4b-ca68-56d5f5533502"},"outputs":[],"source":["model = CrystalGraphConvNet( \n","    original_x_len=ModelConfig.original_x_len,\n","    edge_attr_len=ModelConfig.edge_attr_len,\n","    out_dim=ModelConfig.out_dim,\n","    x_len=ModelConfig.x_len,\n","    n_conv=ModelConfig.n_conv,\n","    n_h_features=ModelConfig.n_h_features,\n","    n_h_layers=ModelConfig.n_h_layers,\n","    learning_rate=ModelConfig.learning_rate,\n",")\n","print(model)\n","print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14df035b-fa6b-4688-98ef-114c6c8fb299","outputId":"743c9fa9-4590-4946-dbee-7dcc2c2e3611"},"outputs":[],"source":["gpus = torch.cuda.device_count()\n","# early_stop = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n","checkpoint = pl.callbacks.ModelCheckpoint(\n","    dirpath=\"content/ckpts/\", \n","    save_top_k=1, \n","    monitor=\"val_loss_mse\",\n","    mode=\"min\",\n",")\n","print(gpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fe6eb4fd-ae37-4a25-be11-b2c6d0d20e66","outputId":"a2e0c9b4-02f8-4612-c926-73b06b8bb2d0"},"outputs":[],"source":["#trainer = pl.Trainer(gpus=gpus, auto_lr_find=True)\n","#lr_finder = trainer.tuner.lr_find(model,train_loader, valid_loader)\n","#fig = lr_finder.plot(suggest=True) # Plot\n","#fig.show()\n","#print(lr_finder.suggestion())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f3e7e14-202a-4db5-81c4-406669ab9d6a"},"outputs":[],"source":["#fig.savefig('learning_rate_energy.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d127b9f-fc9e-412b-aef9-90f0645c49a4"},"outputs":[],"source":["from pytorch_lightning.loggers import CSVLogger\n","\n","logger = CSVLogger(save_dir=\"log/\", name=\"gnn\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"306692d6-81bb-4616-b379-820573a853e2","outputId":"5f1a03bb-e075-402c-ba55-493022bb2830"},"outputs":[],"source":["trainer = pl.Trainer(gpus=gpus, max_epochs=8, log_every_n_steps=10, callbacks=[checkpoint], logger=logger)\n","trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f500f28f-b3bb-4d78-83dc-445fc2390de3","outputId":"e81ad925-7ba7-44ac-d9d4-0290eb0c1703"},"outputs":[],"source":["#import time\n","#start = time.time()\n","trainer.fit(model, train_loader, valid_loader)\n","#print(\"Total time: \", time.time() - start, \"seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"81006192-4228-4711-b745-2f750237d9ad"},"outputs":[],"source":["trainer.save_checkpoint(\"content/ckpts/final.ckpt\")"]},{"cell_type":"markdown","metadata":{"id":"10a826d5-08e2-40a1-b321-f7fc239e32a7"},"source":["# Testing Stage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"69f0b8e0-7d3d-4a78-a930-54ed9ea8bbce","outputId":"148af9d7-d2d1-4da5-b99c-c5b3e40101f1"},"outputs":[],"source":["trainer.test(ckpt_path='best', dataloaders=test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bea1e59-1bb0-4d73-bbb9-435fcd1f59a6","outputId":"c628175b-aae7-4f42-bbd8-51311c349caa"},"outputs":[],"source":["metrics = []\n","for f in glob.glob('log/gnn/*'):\n","    metric_file = f\"{f}/metrics.csv\"\n","    if not os.path.exists(metric_file):\n","        continue\n","        \n","    metrics.append(pd.read_csv(metric_file))\n","\n","metrics = pd.concat(metrics)\n","#display.display(metrics.head())\n","\n","aggreg_metrics = []\n","agg_col = \"epoch\"\n","for i, dfg in metrics.groupby(agg_col):\n","    agg = dict(dfg.mean())\n","    agg[agg_col] = i\n","    aggreg_metrics.append(agg)\n","\n","df_metrics = pd.DataFrame(aggreg_metrics)\n","# display.display(df_metrics.head())\n","\n","df_metrics[[\"train_loss_mse_epoch\", \"val_loss_mse_epoch\"]].plot(grid=True, legend=True, figsize=(10, 8))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29ec1632-b7a4-43ea-a702-60a2f6aa8e59","outputId":"8ddf817a-29b9-4d56-8c90-7e4f1b7ddbf7"},"outputs":[],"source":["metrics = []\n","for f in glob.glob('log/gnn/*'):\n","    metric_file = f\"{f}/metrics.csv\"\n","    if not os.path.exists(metric_file):\n","        continue\n","        \n","    metrics.append(pd.read_csv(metric_file))\n","\n","metrics = pd.concat(metrics)\n","#display.display(metrics.head())\n","\n","aggreg_metrics = []\n","agg_col = \"epoch\"\n","for i, dfg in metrics.groupby(agg_col):\n","    agg = dict(dfg.mean())\n","    agg[agg_col] = i\n","    aggreg_metrics.append(agg)\n","\n","df_metrics = pd.DataFrame(aggreg_metrics)\n","# display.display(df_metrics.head())\n","\n","df_metrics[[\"train_loss_mae_epoch\", \"val_loss_mae_epoch\"]].plot(grid=True, legend=True, figsize=(10, 8))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"f1b9ada7-25a7-4a81-9c52-b3b64ac4c0e4"},"source":["# Prediction Stage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"04f54221-bb43-4f88-8bc3-b3b82f2a942d","outputId":"63e3d667-df47-4de4-c163-b717d6529ef2"},"outputs":[],"source":["final_model_path = checkpoint.best_model_path\n","print(final_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9edfb824-edbf-4fc3-acc5-963865ea6384"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f72fa2da-bd66-44a0-b968-3332229bb89d","outputId":"68b549f1-9971-47bf-f8c9-53fdeb636e95"},"outputs":[],"source":["final_model = CrystalGraphConvNet.load_from_checkpoint(\n","    final_model_path, \n","    original_x_len=ModelConfig.original_x_len,\n","    edge_attr_len=ModelConfig.edge_attr_len,\n","    out_dim=ModelConfig.out_dim,\n","    x_len=ModelConfig.x_len,\n","    n_conv=ModelConfig.n_conv,\n","    n_h_features=ModelConfig.n_h_features,\n","    n_h_layers=ModelConfig.n_h_layers,\n","    learning_rate=ModelConfig.learning_rate,\n",").to(device)\n","final_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fbdd764-55ce-4b02-864f-7294ceb39f65","outputId":"62773018-9f95-4a27-d5a2-6f8f98a79d5c"},"outputs":[],"source":["y_pred, y_real = [], []\n","for i, batch in enumerate(test_loader):\n","    with torch.no_grad():\n","        \n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        x = x.to(device)\n","        edge_attr = edge_attr.to(device)\n","        edge_index = edge_index.to(device)\n","        \n","        pred = final_model(x, edge_attr, edge_index, crystal_x_idx)\n","        \n","        pred = pred.cpu().numpy()\n","        y = y.cpu().numpy()\n","\n","        # y_pred.append(np.concatenate([pred, pred], axis=1))\n","        # y_real.append(np.concatenate([y, y], axis=1))\n","\n","        y_pred.append(pred)\n","        y_real.append(y)\n","\n","        \n","y_pred = np.vstack(y_pred)\n","y_real = np.vstack(y_real)\n","\n","print(y_pred.shape)\n","print(y_real.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0b0618ee-2e8e-4237-9d1e-9a5e9edbb620","outputId":"a930d432-23c5-46cd-aabb-9330d89eff03"},"outputs":[],"source":["idx = 20\n","print(y_real[idx, :5])\n","print(y_pred[idx, :5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"71ae81f3-96ef-4d5c-967c-7d6738aa7d3e","outputId":"3962db42-7767-4c8e-b921-4ad87bb9c1df"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (12, 8)\n","\n","plt.plot(y_real[0:100, 0],'b',  y_pred[0:100, 0], 'r')\n","\n","plt.title('y-real vs y_pred')\n","plt.xlabel('number of records')\n","plt.ylabel('formation energy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1117d9a-f817-453a-b0e0-bb4044ab455d"},"outputs":[],"source":["inv_y_real = scaler.inverse_transform(y_real)\n","inv_y_pred = scaler.inverse_transform(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa046a0b-c4fd-4c77-b834-206c0c9f5dcf"},"outputs":[],"source":["# create a list\n","y_real_list = [item for sublist in inv_y_real.tolist() for item in sublist]\n","y_pred_list = [item for sublist in inv_y_pred.tolist() for item in sublist]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f1027b3-7136-44a0-92b7-4a97d2982f5b","outputId":"316c7c86-9a15-4c34-e860-90359bc27a42"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (12, 8)\n","\n","plt.plot(y_real_list[20:100],'b',  y_pred_list[20:100], 'r')\n","\n","plt.title('y-real vs y_pred')\n","plt.xlabel('number of records')\n","plt.ylabel('formation energy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"712c63ac-8c13-490c-93f8-d32851d0ebcf","outputId":"d2457b85-93fd-4a0c-9cfe-9d709768f8df"},"outputs":[],"source":["# create a dataframe \n","result_df= pd.DataFrame({'real_energy': y_real_list, 'predict_energy': y_pred_list})\n","result_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad76f1b1-3aaa-4fcd-9dcd-88446a8dbc46"},"outputs":[],"source":["result_df.to_csv(\"predict_data.csv\", encoding=\"utf-8\", index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.8.0 64-bit","name":"python380jvsc74a57bd0ba3cbf9c0712703e59f52dbdced9b44e5f9b075148defc511d7f505a968bbe4b"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":5}