{"cells":[{"cell_type":"markdown","metadata":{"id":"aacb166f-e761-4fe2-a1df-3aa5c3c8a544"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3132a9e-cfea-4e55-ad60-a1388994dc7e"},"outputs":[],"source":["# Import Libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import glob\n","import json\n","import csv\n","from IPython import display\n","import matplotlib.pyplot as plt\n","import hashlib"]},{"cell_type":"markdown","metadata":{"id":"952081da-cabe-4d5c-b5dc-9fbd00fc2ea4"},"source":["# Dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ee4a5fcd-4827-49b7-bf77-627588c991a7","outputId":"4c9c5482-66a8-42fb-ad45-1c3b8a688d16"},"outputs":[],"source":["path = 'data'\n","csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n","\n","dfs = []\n","for i, f in enumerate(csv_files):\n","    df = pd.read_csv(f, engine=\"python\")\n","    df['root'] = f'{i+1}'\n","    dfs.append(df)\n","\n","final_data = pd.concat(dfs)\n","#final_data.to_csv(\"./dataset2/data.csv\", encoding=\"utf-8\", index=False)\n","final_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fcdafe08-1ccf-43eb-a34c-f66529cd9fec"},"outputs":[],"source":["#final_data.to_csv(\"data.csv\", encoding=\"utf-8\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"294a2627-d96b-4fe1-9bb7-78d8c101c6d6","outputId":"fa93b85f-6f7b-450f-ab3c-98fe1c297799"},"outputs":[],"source":["print(final_data['root'].shape)\n","print(final_data['root'].unique())\n","print(len(final_data[final_data['root'] == '7']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f061f6d1-70c7-46df-8100-84a648ea6a17","outputId":"928382d5-3830-4927-f26b-d5d27cd571e9"},"outputs":[],"source":["final_data.info()"]},{"cell_type":"markdown","metadata":{"id":"05adcd0b-9217-418b-b5be-73602b7f95d7"},"source":["# Train-Valid-Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4f3815ad-2c04-4e4f-846d-659bf4c1ccb3","outputId":"bed48b3c-d11a-483e-8b94-0a25ecf031e1"},"outputs":[],"source":["df = final_data.copy()\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aca1ff4-7743-47ed-98f3-b1a0b6352d80"},"outputs":[],"source":["# Train-test split\n","from sklearn.model_selection import train_test_split\t\n","\n","tmp, test_df = train_test_split(df, test_size=0.2, random_state=101, stratify=df['root'])\n","train_df, valid_df = train_test_split(tmp, test_size=0.1, random_state=101, stratify=tmp['root'])\n","\n","train_df = train_df.drop('root', axis=1).reset_index(drop=True)\n","valid_df = valid_df.drop('root', axis=1).reset_index(drop=True)\n","test_df = test_df.drop('root', axis=1).reset_index(drop=True)\n","\n","train_df.to_csv(\"dataset/org-train.csv\", encoding=\"utf-8\", index=False)\n","valid_df.to_csv(\"dataset/org-valid.csv\", encoding=\"utf-8\", index=False)\n","test_df.to_csv(\"dataset/org-test.csv\", encoding=\"utf-8\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfbbd285-7179-404e-aef2-0c21932e6289"},"outputs":[],"source":["from sklearn import preprocessing\n","x_cols = list(train_df.columns)[1:-1]\n","scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n","scaler.fit(train_df[x_cols])\n","\n","\n","new_train_df = train_df.copy()\n","new_train_df[x_cols] = scaler.transform(train_df[x_cols])\n","\n","new_valid_df = valid_df.copy()\n","new_valid_df[x_cols] = scaler.transform(valid_df[x_cols])\n","\n","new_test_df = test_df.copy()\n","new_test_df[x_cols] = scaler.transform(test_df[x_cols])\n","\n","\n","new_train_df.to_csv(\"dataset/train.csv\", encoding=\"utf-8\", index=False)\n","new_valid_df.to_csv(\"dataset/valid.csv\", encoding=\"utf-8\", index=False)\n","new_test_df.to_csv(\"dataset/test.csv\", encoding=\"utf-8\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d32861e-5335-4b3f-8a85-2686ff4a05ac","outputId":"86503b15-71cc-4615-bc0f-335d6a093fbf"},"outputs":[],"source":["new_train_df.shape, new_valid_df.shape, new_test_df.shape"]},{"cell_type":"markdown","metadata":{"id":"aa719cfa-705a-4a76-9e5c-445a6873a42f"},"source":["# Dataset Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41610df4-ae20-4dcd-b703-1e5079aef453","outputId":"c5e41719-9cbf-4189-cc78-8de9c2915fc2"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","from pymatgen.core.structure import Structure\n","\n","import pandas as pd\n","import numpy as np\n","import json\n","import warnings\n","\n","\n","class GaussianDistance(object):\n","    \"\"\"\n","    Expands the distance by Gaussian basis.\n","\n","    Unit: angstrom\n","    \"\"\"\n","    def __init__(self, dmin, dmax, step, var=None):\n","        \"\"\"\n","        Parameters\n","        ----------\n","\n","        dmin: float\n","          Minimum interatomic distance\n","        dmax: float\n","          Maximum interatomic distance\n","        step: float\n","          Step size for the Gaussian filter\n","        \"\"\"\n","        assert dmin < dmax\n","        assert dmax - dmin > step\n","        self.filter = np.arange(dmin, dmax+step, step)\n","        if var is None:\n","            var = step\n","        self.var = var\n","\n","    def expand(self, distances):\n","        \"\"\"\n","        Apply Gaussian disntance filter to a numpy distance array\n","\n","        Parameters\n","        ----------\n","\n","        distance: np.array shape n-d array\n","          A distance matrix of any shape\n","\n","        Returns\n","        -------\n","        expanded_distance: shape (n+1)-d array\n","          Expanded distance matrix with the last dimension of length\n","          len(self.filter)\n","        \"\"\"\n","        return np.exp(-(distances[..., np.newaxis] - self.filter)**2 /\n","                      self.var**2)\n","\n","\n","class AtomInitializer(object):\n","    \"\"\"\n","    Base class for intializing the vector representation for atoms.\n","\n","    !!! Use one AtomInitializer per dataset !!!\n","    \"\"\"\n","    def __init__(self, atom_types):\n","        self.atom_types = set(atom_types)\n","        self._embedding = {}\n","\n","    def get_atom_fea(self, atom_type):\n","        assert atom_type in self.atom_types\n","        return self._embedding[atom_type]\n","\n","    def load_state_dict(self, state_dict):\n","        self._embedding = state_dict\n","        self.atom_types = set(self._embedding.keys())\n","        self._decodedict = {idx: atom_type for atom_type, idx in\n","                            self._embedding.items()}\n","\n","    def state_dict(self):\n","        return self._embedding\n","\n","    def decode(self, idx):\n","        if not hasattr(self, '_decodedict'):\n","            self._decodedict = {idx: atom_type for atom_type, idx in\n","                                self._embedding.items()}\n","        return self._decodedict[idx]\n","\n","\n","class AtomCustomJSONInitializer(AtomInitializer):\n","    \"\"\"\n","    Initialize atom feature vectors using a JSON file, which is a python\n","    dictionary mapping from element number to a list representing the\n","    feature vector of the element.\n","\n","    Parameters\n","    ----------\n","\n","    elem_embedding_file: str\n","        The path to the .json file\n","    \"\"\"\n","    def __init__(self, elem_embedding_file):\n","        with open(elem_embedding_file) as f:\n","            elem_embedding = json.load(f)\n","        elem_embedding = {int(key): value for key, value\n","                          in elem_embedding.items()}\n","        atom_types = set(elem_embedding.keys())\n","        super(AtomCustomJSONInitializer, self).__init__(atom_types)\n","        for key, value in elem_embedding.items():\n","            self._embedding[key] = np.array(value, dtype=float)\n","            \n","\n","class CrystalDataset(Dataset):\n","\n","    def __init__(self, data_path, atom_init_file=\"./atom_init.json\", max_num_nbr=12, radius=8, dmin=0, step=0.2):\n","        #self.df = pd.read_json(data_path, orient='records', lines=True)\n","        self.df = pd.read_csv(data_path)\n","        self.max_num_nbr, self.radius = max_num_nbr, radius\n","        \n","        self.ari = AtomCustomJSONInitializer(atom_init_file)\n","        self.gdf = GaussianDistance(dmin=dmin, dmax=self.radius, step=step)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        sample = self.df.iloc[idx].values\n","        struct, target, cif_id = sample[0], sample[1:-1], sample[-1]\n","        #struct, target, cif_id = sample[0], sample[1], sample[2]\n","\n","        crystal = Structure.from_file(struct)\n","        #crystal = Structure.from_dict(struct)\n","        atom_fea = np.vstack([self.ari.get_atom_fea(crystal[i].specie.number) for i in range(len(crystal))])\n","        atom_fea = torch.Tensor(atom_fea)\n","        all_nbrs = crystal.get_all_neighbors(self.radius, include_index=True)\n","        all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]\n","        nbr_fea_idx, nbr_fea = [], []\n","        for nbr in all_nbrs:\n","            if len(nbr) < self.max_num_nbr:\n","                warnings.warn('{} not find enough neighbors to build graph. '\n","                              'If it happens frequently, consider increase '\n","                              'radius.'.format(cif_id))\n","                nbr_fea_idx.append(list(map(lambda x: x[2], nbr)) +\n","                                   [0] * (self.max_num_nbr - len(nbr)))\n","                nbr_fea.append(list(map(lambda x: x[1], nbr)) +\n","                               [self.radius + 1.] * (self.max_num_nbr -\n","                                                     len(nbr)))\n","            else:\n","                nbr_fea_idx.append(list(map(lambda x: x[2],\n","                                            nbr[:self.max_num_nbr])))\n","                nbr_fea.append(list(map(lambda x: x[1],\n","                                        nbr[:self.max_num_nbr])))\n","        nbr_fea_idx, nbr_fea = np.array(nbr_fea_idx), np.array(nbr_fea)\n","        nbr_fea = self.gdf.expand(nbr_fea)\n","        atom_fea = torch.Tensor(atom_fea)\n","        nbr_fea = torch.Tensor(nbr_fea)\n","        nbr_fea_idx = torch.LongTensor(nbr_fea_idx)\n","        target = torch.Tensor(np.array(target, dtype=float))\n","        #target = torch.Tensor([float(target)])\n","\n","        x, edge_attr, edge_index = atom_fea, nbr_fea, nbr_fea_idx\n","        return (x, edge_attr, edge_index), target, cif_id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"740a8b5d-94de-41d5-95b4-3228cebc95b4"},"outputs":[],"source":["train_dataset = CrystalDataset(\"dataset/train.csv\", max_num_nbr=12, radius=8)\n","valid_dataset = CrystalDataset(\"dataset/valid.csv\", max_num_nbr=12, radius=8)\n","test_dataset = CrystalDataset(\"dataset/test.csv\", max_num_nbr=12, radius=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ef4ce76-4525-474a-bfee-30f42bdd13ec","outputId":"7e1f857c-723b-499f-8eaf-478cd744b7db"},"outputs":[],"source":["print(train_dataset[0][0][0].shape)\n","print(train_dataset[0][0][1].shape)\n","print(train_dataset[0][0][2].shape)\n","print(train_dataset[0][1].shape)\n","print(train_dataset[0][2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67a71f66-cb9c-482a-876f-d3645496b2ca"},"outputs":[],"source":["def collate_fn(data_list):\n","    batch_x, batch_edge_attr, batch_edge_index = [], [], []\n","    crystal_x_idx, batch_target = [], []\n","    batch_ids = []\n","    base_idx = 0\n","    \n","    for i, ((x, edge_attr, edge_index), target, _id) in enumerate(data_list):\n","        n_i = x.shape[0]\n","        batch_x.append(x)\n","        batch_edge_attr.append(edge_attr)\n","        batch_edge_index.append(edge_index + base_idx)\n","        \n","        new_idx = torch.LongTensor(np.arange(n_i) + base_idx)\n","        crystal_x_idx.append(new_idx)\n","        batch_target.append(target)\n","        batch_ids.append(_id)\n","        base_idx += n_i\n","    \n","    \n","    batch_x = torch.cat(batch_x, dim=0)\n","    batch_edge_attr = torch.cat(batch_edge_attr, dim=0)\n","    batch_edge_index = torch.cat(batch_edge_index, dim=0)\n","    batch_target = torch.stack(batch_target, dim=0)\n","    \n","    return (batch_x, batch_edge_attr, batch_edge_index, crystal_x_idx), batch_target, batch_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2c73949f-dbd4-4dda-a04d-364f50c28cd6"},"outputs":[],"source":["batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96a63e9c-98f9-43a0-a49d-649f5621c07a","outputId":"329008c7-6918-4792-d1ec-b269842e0616"},"outputs":[],"source":["for batch in train_loader:\n","    print(\"x\", batch[0][0].shape)\n","    print(\"edge_attr\", batch[0][1].shape)\n","    print(\"edge_index\", batch[0][2].shape)\n","#    print(\"crystal_x_idx\", batch[0][3])\n","    \n","#    print(batch[1])\n","#    print(batch[2])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"fb49a614-43b9-487b-af2d-3e30438770f0"},"source":["# CGConv model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b45168a6-4c15-4d05-b0b9-a24402b1b7ec","outputId":"a80d2d2c-908e-4348-deb4-49c2a5d89a43"},"outputs":[],"source":["structures, _, _ = train_dataset[0]\n","original_x_len = structures[0].shape[-1]\n","edge_attr_len = structures[1].shape[-1]\n","\n","print(original_x_len, edge_attr_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9cb20fe-97bc-4d25-97f8-05ef056cd51c"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","\n","import pytorch_lightning as pl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ec982ad2-d492-453d-b27a-85bf3dac24bb"},"outputs":[],"source":["class ConvLayer(nn.Module):\n","    def __init__(self, x_len, edge_attr_len):\n","        super(ConvLayer, self).__init__()\n","        \n","        self.x_len = x_len\n","        self.edge_attr_len = edge_attr_len\n","        self.fc = nn.Linear(2 * self.x_len + self.edge_attr_len, 2 * self.x_len)\n","        self.sigmoid = nn.Sigmoid()\n","        self.softplus1 = nn.Softplus()\n","        self.bn1 = nn.BatchNorm1d(2 * self.x_len)\n","        self.bn2 = nn.BatchNorm1d(self.x_len)\n","        self.softplus2 = nn.Softplus()\n","    \n","    def forward(self, x, edge_attr, edge_index):\n","        N, M = edge_index.shape\n","        \n","        x_nbr = x[edge_index, :]\n","        nbrs = torch.cat([x.unsqueeze(1).expand(N, M, self.x_len), x_nbr, edge_attr], dim=2)\n","        gated = self.fc(nbrs)\n","        gated = self.bn1(gated.view(-1, self.x_len * 2)).view(N, M, self.x_len * 2)\n","        \n","        nbr_filter, nbr_core = gated.chunk(2, dim=2)\n","        nbr_filter = self.sigmoid(nbr_filter)\n","        nbr_core = self.softplus1(nbr_core)\n","        \n","        nbr_sum = torch.sum(nbr_filter * nbr_core, dim=1)\n","        nbr_sum = self.bn2(nbr_sum)\n","        out = self.softplus2(x + nbr_sum)\n","        return out\n","        \n","\n","class CrystalGraphConvNet(pl.LightningModule):\n","\n","    def __init__(\n","        self, \n","        original_x_len,\n","        edge_attr_len,\n","        out_dim=381,\n","        x_len=64,\n","        n_conv=3,\n","        n_h_features=128,\n","        n_h_layers=1,\n","        learning_rate=1e-3,\n","        bias=True\n","    ):\n","        # Inheritances\n","        super().__init__()\n","\n","        # Params\n","        self.learning_rate = learning_rate\n","\n","        # Embedding\n","        self.embedding = nn.Linear(original_x_len, x_len)\n","\n","        # CGC layer\n","        self.convs = nn.ModuleList([\n","            ConvLayer(x_len=x_len, edge_attr_len=edge_attr_len)\n","            for _ in range(n_conv)\n","        ])        \n","\n","        self.fc = nn.ModuleList(\n","            [nn.Linear(x_len, n_h_features)]\n","            +\n","            [nn.Linear(n_h_features, n_h_features) for _ in range(n_h_layers - 1)]\n","        )\n","        self.ac = nn.ModuleList(\n","            [nn.Softplus()]\n","            +\n","            [nn.Softplus() for _ in range(n_h_layers - 1)]\n","        )\n","        \n","        #self.sigmoid = nn.Sigmoid() # change one\n","        self.out = nn.Linear(n_h_features, out_dim)\n","\n","    def forward(self, x, edge_attr, edge_index, crystal_x_idx):\n","        \n","        hidden = self.embedding(x)\n","        \n","        \n","        for conv in self.convs:\n","            hidden = conv(hidden, edge_attr, edge_index)\n","            \n","        # Pooling\n","        hidden =self.pooling(hidden, crystal_x_idx)\n","        \n","        # Fully-connection\n","        for fc, ac in zip(self.fc, self.ac):\n","            hidden = ac(fc(hidden))\n","\n","        # Apply a final (linear) classifier.\n","        #out = self.sigmoid(self.out(hidden)) # change two\n","        out = self.out(hidden) \n","\n","        return out\n","    \n","    def pooling(self, x, crystal_x_idx):\n","        assert sum([len(idx) for idx in crystal_x_idx]) == x.data.shape[0]\n","\n","        hidden = torch.cat(\n","            [torch.mean(x[idx], dim=0, keepdim=True) for idx in crystal_x_idx],\n","            dim=0\n","        )\n","\n","        return hidden\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=0.01)\n","        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n","        return (\n","            {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n","        )\n","\n","    def training_step(self, batch, batch_idx):\n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        y_hat = self(x, edge_attr, edge_index, crystal_x_idx)\n","\n","        loss = F.mse_loss(y_hat, y)\n","        loss_mae = F.l1_loss(y_hat, y)\n","        \n","        self.log(\n","            'train_loss_mse', loss, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        self.log(\n","            'train_loss_mae', loss_mae, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        return loss    \n","\n","    def validation_step(self, batch, batch_idx):\n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        y_hat = self(x, edge_attr, edge_index, crystal_x_idx)\n","\n","        loss = F.mse_loss(y_hat, y)\n","        loss_mae = F.l1_loss(y_hat, y)\n","        \n","        self.log(\n","            'valid_loss_mse', loss, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        self.log(\n","            'valid_loss_mae', loss_mae, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        y_hat = self(x, edge_attr, edge_index, crystal_x_idx)\n","\n","        loss = F.mse_loss(y_hat, y)\n","        loss_mae = F.l1_loss(y_hat, y)\n","        \n","        self.log(\n","            'test_loss_mse', loss, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        self.log(\n","            'test_loss_mae', loss_mae, \n","            on_step=True, on_epoch=True, prog_bar=True, logger=True,\n","            batch_size=y_hat.size(0)\n","        )\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66ff289d-7e26-4bce-8ea1-b7abbd8318ca"},"outputs":[],"source":["from dataclasses import dataclass\n","\n","\n","@dataclass\n","class ModelConfig:\n","    original_x_len = original_x_len\n","    edge_attr_len = edge_attr_len\n","    out_dim = 381\n","    x_len = 64\n","    n_conv = 3\n","    n_h_features = 128\n","    n_h_layers = 1\n","    learning_rate = 1e-2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a132f2ae-f262-44ae-84e0-218dfb11902f","outputId":"1df7ce04-d960-4800-b76a-c8f1e753321a"},"outputs":[],"source":["model = CrystalGraphConvNet( \n","    original_x_len=ModelConfig.original_x_len,\n","    edge_attr_len=ModelConfig.edge_attr_len,\n","    out_dim=ModelConfig.out_dim,\n","    x_len=ModelConfig.x_len,\n","    n_conv=ModelConfig.n_conv,\n","    n_h_features=ModelConfig.n_h_features,\n","    n_h_layers=ModelConfig.n_h_layers,\n","    learning_rate=ModelConfig.learning_rate,\n",")\n","print(model)\n","print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79f75d5a-e357-4b65-83a6-220cff35f7a0","outputId":"bb34d673-3c84-4e01-9216-23e1fc3d4e09"},"outputs":[],"source":["for batch in train_loader:\n","    (batch_x, batch_edge_attr, batch_edge_index, crystal_x_idx), batch_target, batch_ids = batch\n","\n","    out = model(batch_x, batch_edge_attr, batch_edge_index, crystal_x_idx)\n","    print(out.shape)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"7c52bab5-af12-44d8-bd41-2d08f5b5bf3e"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7493a03b-c9c3-4709-b9f6-3361c4d506e2","outputId":"ac92656a-4b8e-483e-b35a-b847c6968262"},"outputs":[],"source":["model = CrystalGraphConvNet( \n","    original_x_len=ModelConfig.original_x_len,\n","    edge_attr_len=ModelConfig.edge_attr_len,\n","    out_dim=ModelConfig.out_dim,\n","    x_len=ModelConfig.x_len,\n","    n_conv=ModelConfig.n_conv,\n","    n_h_features=ModelConfig.n_h_features,\n","    n_h_layers=ModelConfig.n_h_layers,\n","    learning_rate=ModelConfig.learning_rate,\n",")\n","print(model)\n","print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c33b23a6-852e-403c-9aff-5eb0b99f2c5a","outputId":"4f8fc2e0-ac46-4543-98ee-b2e06502df88"},"outputs":[],"source":["gpus = torch.cuda.device_count()\n","# early_stop = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n","checkpoint = pl.callbacks.ModelCheckpoint(\n","    dirpath=\"content/ckpts/\", \n","    save_top_k=1, \n","    monitor=\"val_loss_mse\",\n","    mode=\"min\",\n",")\n","print(gpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7187d1f-f7e7-4c4d-b60d-471058a3b062"},"outputs":[],"source":["from pytorch_lightning.loggers import CSVLogger\n","\n","logger = CSVLogger(save_dir=\"log/\", name=\"gnn\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3a8babae-375e-4bf5-b2e5-8acc2cc6e056","outputId":"6f9ed82a-9c72-4a7f-965c-39f06a519ed2"},"outputs":[],"source":["# trainer = pl.Trainer(gpus=gpus, strategy=strategy, max_epochs=50, log_every_n_steps=5, callbacks=[checkpoint])\n","trainer = pl.Trainer(gpus=gpus, max_epochs=5, log_every_n_steps=10, callbacks=[checkpoint], logger=logger)\n","trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"973a0ec6-ef6d-41a6-9fac-995eb9383c4c","outputId":"7e60c432-097e-4ef9-82fc-32b8af6971d9"},"outputs":[],"source":["trainer.fit(model, train_loader, valid_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7115f333-1f3a-48d5-b644-eb0f0c9d081d"},"outputs":[],"source":["trainer.save_checkpoint(\"content/ckpts/final.ckpt\")"]},{"cell_type":"markdown","metadata":{"id":"741a55e2-c380-431e-ace8-eb45c6f2f886"},"source":["# Testing stage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6214b3b0-6427-47a8-814a-9ee1309041e3","outputId":"07603ac3-c671-4ecb-8ce1-4b5e123ae99f"},"outputs":[],"source":["trainer.test(ckpt_path='best', dataloaders=test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03be91f9-1765-40da-8914-7ee93ee244e0"},"outputs":[],"source":["metrics = []\n","for f in glob.glob('log/gnn/*'):\n","    metric_file = f\"{f}/metrics.csv\"\n","    if not os.path.exists(metric_file):\n","        continue\n","        \n","    metrics.append(pd.read_csv(metric_file))\n","\n","metrics = pd.concat(metrics)\n","#display.display(metrics.head())\n","\n","aggreg_metrics = []\n","agg_col = \"epoch\"\n","for i, dfg in metrics.groupby(agg_col):\n","    agg = dict(dfg.mean())\n","    agg[agg_col] = i\n","    aggreg_metrics.append(agg)\n","\n","df_metrics = pd.DataFrame(aggreg_metrics)\n","# display.display(df_metrics.head())\n","\n","df_metrics[[\"train_loss_mse_epoch\", \"val_loss_mse_epoch\"]].plot(grid=True, legend=True, figsize=(10, 8))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ae02c66-f57c-42f4-925c-aa7f100924cd"},"outputs":[],"source":["metrics = []\n","for f in glob.glob('log/gnn/*'):\n","    metric_file = f\"{f}/metrics.csv\"\n","    if not os.path.exists(metric_file):\n","        continue\n","        \n","    metrics.append(pd.read_csv(metric_file))\n","\n","metrics = pd.concat(metrics)\n","#display.display(metrics.head())\n","\n","aggreg_metrics = []\n","agg_col = \"epoch\"\n","for i, dfg in metrics.groupby(agg_col):\n","    agg = dict(dfg.mean())\n","    agg[agg_col] = i\n","    aggreg_metrics.append(agg)\n","\n","df_metrics = pd.DataFrame(aggreg_metrics)\n","# display.display(df_metrics.head())\n","\n","df_metrics[[\"train_loss_mae_epoch\", \"val_loss_mae_epoch\"]].plot(grid=True, legend=True, figsize=(10, 8))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4179e8eb-f7bd-4243-8659-abb0466b3c59"},"source":["# Prediction stage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e15e6403-346d-4dc9-b071-33ce1db49ace"},"outputs":[],"source":["final_model_path = checkpoint.best_model_path\n","print(final_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7453e7d-5022-4964-8dd9-acd564dc1740"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18f8b4c1-20c4-46b0-99ba-996a9bdb551e","outputId":"5bfe0bae-5a49-40ab-8ebb-9d13a37ac45c"},"outputs":[],"source":["final_model = CrystalGraphConvNet.load_from_checkpoint(\n","    final_model_path, \n","    original_x_len=ModelConfig.original_x_len,\n","    edge_attr_len=ModelConfig.edge_attr_len,\n","    out_dim=ModelConfig.out_dim,\n","    x_len=ModelConfig.x_len,\n","    n_conv=ModelConfig.n_conv,\n","    n_h_features=ModelConfig.n_h_features,\n","    n_h_layers=ModelConfig.n_h_layers,\n","    learning_rate=ModelConfig.learning_rate,\n",").to(device)\n","final_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35494e94-fb9b-4682-b240-7ef97c7a6f9c","outputId":"93044cca-ab15-4cf7-a825-3a276ea35fc9"},"outputs":[],"source":["y_pred, y_real = [], []\n","for i, batch in enumerate(train_loader):\n","    with torch.no_grad():\n","        \n","        (x, edge_attr, edge_index, crystal_x_idx), y, ids = batch\n","        x = x.to(device)\n","        edge_attr = edge_attr.to(device)\n","        edge_index = edge_index.to(device)\n","        \n","        pred = final_model(x, edge_attr, edge_index, crystal_x_idx)\n","        \n","        pred = pred.cpu().numpy()\n","        y = y.cpu().numpy()\n","\n","        # y_pred.append(np.concatenate([pred, pred], axis=1))\n","        # y_real.append(np.concatenate([y, y], axis=1))\n","\n","        y_pred.append(pred)\n","        y_real.append(y)\n","        break\n","\n","        \n","y_pred = np.vstack(y_pred)\n","y_real = np.vstack(y_real)\n","\n","print(y_pred.shape)\n","print(y_real.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51db3a6c-3448-4584-8443-0364567e906b","outputId":"39c2d4a2-b2f4-4c44-ba23-084f768991cc"},"outputs":[],"source":["idx = 20\n","print(y_pred[idx, 200:210].tolist())\n","print(y_real[idx, 200:210].tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2a8ff9a2-4711-4eaf-9008-b9a54d20b038","outputId":"140cbe40-15d2-40e7-a874-493bdd2393d3"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (12, 8)\n","\n","plt.plot(y_real[20, :],'b', y_pred[20, :],'r')\n","\n","plt.title('y-real vs y_pred')\n","plt.xlabel('number of records')\n","plt.ylabel('intensity values')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05c06269-40a0-4b1d-ad94-02af83774158","outputId":"53c0cc17-504c-4964-f7b2-2f3d25985226"},"outputs":[],"source":["fig, (ax1, ax2) = plt.subplots(2, figsize=(12,8))\n","\n","\n","yr = y_real[100, :]\n","yp = y_pred[100, :]\n","\n","ax1.plot(yr)\n","ax1.set_title('y_real')\n","ax1.set_ylabel('intensity value')\n","ax2.plot(yp, 'r')\n","ax2.set_title('y_pred')\n","ax2.set_xlabel('number of records (381)')\n","ax2.set_ylabel('intensity value')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a651080c-d3f0-47c3-88c4-d77bbc003bff"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.8.0 64-bit","name":"python380jvsc74a57bd0ba3cbf9c0712703e59f52dbdced9b44e5f9b075148defc511d7f505a968bbe4b"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":5}